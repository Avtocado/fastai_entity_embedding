# -*- coding: utf-8 -*-
"""Copy of FinalFinalEmbeddings.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10EQe1_n0iK0uMiH43sU4gANdUceYq5R-
"""

import numpy as np
from sklearn.metrics import classification_report
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn import preprocessing
from sklearn.ensemble import RandomForestClassifier
import altair as alt
from sklearn.decomposition import PCA
from fastai.tabular.all import *

class EntEmbedding():

  def __init__(self, df, target):
    '''
    Parameters
    ----------
    df : dataframe 
       features and target you want to use
    target : str
       column name of your target 
    '''
    self.df = df
    self.target = target

  def cat_split(self, max_card=100):

      self.cont_names, self.cat_names = cont_cat_split(self.df, max_card = max_card, dep_var=self.target)
      self.procs_nn = [Categorify, FillMissing, Normalize]

      print(len(self.cont_names), "Continous Features:", self.cont_names, '\n', len(self.cat_names), "Categorical Features:", self.cat_names) 
    



  def find_alpha(self, regression=True, batch_size=1024, layer_size=[500, 250],  metrics = rmse):
      '''
      max_card : int
            if nunique > max_card value, it will be identified as continous, otherwis caregorical
      batch_size : int
            batch size used during training
      layer_size : list
            layer widths with to layers
      metrics : function
            uses sklearn metric names

      '''
      if regression:
         self.df.loc[:, self.target] = self.df.loc[:, self.target].astype(np.float32)
         to_nn = TabularPandas(self.df, self.procs_nn, self.cat_names, self.cont_names,
                             splits=RandomSplitter()(range_of(self.df)), y_names=self.target)
         self.dls = to_nn.dataloaders(batch_size)
         y = to_nn.train.y
         self.learn = tabular_learner(self.dls, layers=layer_size, y_range=(y.min(),y.max()), n_out=1, 
                                      metrics = metrics)
      else:

         to_nn = TabularPandas(self.df, self.procs_nn, self.cat_names, self.cont_names,
                             splits=RandomSplitter()(range_of(self.df)), y_names=self.target, y_block=CategoryBlock())
         self.dls = to_nn.dataloaders(batch_size)
        
         self.learn = tabular_learner(self.dls, layers=layer_size, 
                                      metrics = metrics)

      self.alpha =  self.learn.lr_find()
      print(self.alpha)

  def fit(self, epochs = 50, alpha = 1e-3):
     '''
     epochs : int
        number of epochs model will be trained during fit
     alpha : int
        learning rate. preferrably you should set this parameter to the value returned by .find_alpha() method
     '''
     self.learn.fit_one_cycle(n_epoch=epochs, lr_max=alpha)
  
  def embed_features(self, learner, xs, variable):
    #parameters for embed_features(model.learn, model.dls.train.xs, 'column_you_want_visualization_for')  
    xs = xs.copy()
    self.var = variable
    new = []
    for i, feature in enumerate(learner.dls.cat_names):
        emb = learner.model.embeds[i]
        new_feat = pd.DataFrame(emb(tensor(xs[feature], dtype=torch.int64)), index=xs.index, columns=[f'{feature}_{j}' for j in range(emb.embedding_dim)])
        new.append(new_feat)
        ix = learner.dls.cat_names.index(variable)
        self.var_vals = list(self.df[variable].astype('category').cat.categories.values)
        emb_mx = to_np(next(learner.model.embeds[ix].parameters()))
        self.X_emb = PCA(n_components=2).fit_transform(emb_mx)
    new = pd.concat(new, axis=1)
        
    return new


  def visualize(self):
          emb_df = pd.DataFrame(self.X_emb[1:], columns=['Dim1', 'Dim2'])
          emb_df[self.var]=np.array(self.var_vals)
          points = alt.Chart(emb_df).mark_circle(size=60).encode(
              x='Dim1',
              y='Dim2',
              tooltip=[self.var]
          )

          text = points.mark_text(
              align='left',
              baseline='middle',
              dx=7
          ).encode(
              text=self.var
          )

          graph=points + text
                     

          return graph